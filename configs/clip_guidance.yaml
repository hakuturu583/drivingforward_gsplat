predict:
  model_config: configs/nuscenes/main.yaml
  split: eval_MF
  index: 0
  torchscript_dir: torchscript
  novel_view_mode: MF

training:
  device: cuda
  steps: 1000
  # lr: 0.001
  sh_lr: 0.005
  opacity_lr: 0.0002
  optimize_opacity: true
  seed: 0
  log_every: 10
  save_every: 100

pose_jitter:
  translation_m: 0.1
  yaw_deg: 5.0
  pitch_deg: 0.0
  batch_size: 32
  base_cameras:
    - CAM_FRONT
    - CAM_FRONT_RIGHT
    - CAM_FRONT_LEFT
    - CAM_BACK_RIGHT
    - CAM_BACK_LEFT
    - CAM_BACK
  background_color:
    - 1.0
    - 1.0
    - 1.0

clip_loss:
  model_id: openai/clip-vit-base-patch32
  prompts:
    - "sunset"
  weight: 0.001
  image_size: null

edge_loss:
  weight: 0.1
  sigma: 0.4
  low_threshold: 0.05
  high_threshold: 0.12
  render_low_threshold: 0.12
  render_high_threshold: 0.2
  ref_low_threshold: 0.1
  ref_high_threshold: 0.2
  soft_k: 5.0

sh_reg:
  weight: 0.1
  degree_weights:
    - 0.2
    - 0.5
    - 1.0
    - 2.0
    - 3.0
  norm: l2

musiq_loss:
  model_id: musiq
  weight: 1.0
  image_size: null

output:
  dir: output/clip_guidance
  ply_name: optimized_inria.ply
  save_initial: true
  save_renders_every: 100
